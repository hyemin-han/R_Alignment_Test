# bfs
bf.pss.1.0 <- bayes_factor(pss.1,pss.0,log=T)
model.mediator.0 <- bf(sps ~  gender + education + work_location + age+
SSS_faml+ relationship_status+
(1|residing_country))
model.pss.0 <- bf(pss ~
gender + education + work_location + age+
SSS_faml+ relationship_status+
(1|residing_country))
pss.0 <- brms::brm( model.pss.0+model.mediator.0+set_rescor(F) ,
data=data.filtered, family = gaussian(),
cores=4,chains=4, save_pars = save_pars(all = T),
sample_prior ='yes', seed=1660415,prior=prior.coef)
# bfs
bf.pss.1.0 <- bayes_factor(pss.1,pss.0,log=T)
bf.pss.1.0
save.image("~/Documents/GitHub/COVIDiSTRESS2_Stress/R1/Big_Picture/big.res.RData")
load("~/Documents/GitHub/COVIDiSTRESS2_Stress/R1/Big_Picture/big.pss.RData")
model.mediator.f <- bf(sps ~  identity+gender + education + work_location + age+
SSS_faml+ relationship_status)
model.pss.f <- bf(pss ~ primary_stressor_avg + primary_stressor_avg*sps +
secondary*identity + secondary*sps +
gender + education + work_location + age+
SSS_faml+ relationship_status)
pss.f <- brms::brm( model.pss.f+model.mediator.f+set_rescor(F) ,
data=data.filtered, family = gaussian(),
cores=4,chains=4, save_pars = save_pars(all = T),
sample_prior ='yes', seed=1660415,prior=prior.coef)
bf.pss.2.f <- bayes_factor(pss.2,pss.f,log=T)
bf.pss.2.f
save.image("~/Documents/GitHub/COVIDiSTRESS2_Stress/R1/Big_Picture/big.pss.RData")
library(rworldmap)
library(RColorBrewer)
sPDF <-getMap()
# create data
data_to_map <- matrix(nrow=nrow(countryRegions),ncol=1)
# for
for (i in 1:nrow(countryRegions)){
# check NA
if (is.na(countryRegions[i,'GEO3'])){
next
}
# start with Australia
if (countryRegions[i,'GEO3'] =='Australia and New Zealand'){
data_to_map[i,1]<-      .19
}
if (countryRegions[i,'GEO3'] == 'Central Asia'){
data_to_map[i,1]<-
.17
}
if (countryRegions[i,'GEO3'] == 'NW Pacific and East Asia'){
data_to_map[i,1]<-
.23
}
if (countryRegions[i,'GEO3'] == 'Eastern Europe' | countryRegions[i,'GEO3'] == 'Central Europe'){
data_to_map[i,1]<-
.11
}
if (countryRegions[i,'GEO3'] == 'Caribbean' | countryRegions[i,'GEO3'] == 'Meso-America'|
countryRegions[i,'GEO3'] == 'South America'){
data_to_map[i,1]<-
.14
}
if (countryRegions[i,'GEO3'] == 'North Africa'){
data_to_map[i,1]<-
-.49
}
if (countryRegions[i,'GEO3'] == 'Canada'|
countryRegions[i,'GEO3'] == 'US'){
data_to_map[i,1]<-
.29
}
if (countryRegions[i,'GEO3'] == 'Southeast Asia'){
data_to_map[i,1]<-
.29
}
if (countryRegions[i,'GEO3'] == 'South Asia'){
data_to_map[i,1]<-
.13
}
if (countryRegions[i,'GEO3'] == 'Southern Africa'|
countryRegions[i,'GEO3'] == 'Eastern Africa'|
countryRegions[i,'GEO3'] == 'Central Africa'|
countryRegions[i,'GEO3'] == 'Western Africa'| countryRegions[i,'GEO3'] == 'Western Indian Ocean'|
countryRegions[i,'ADMIN'] == 'South Sudan'){
data_to_map[i,1]<-
.09
}
if (countryRegions[i,'GEO3'] == 'Mashriq'|countryRegions[i,'GEO3'] == 'Arabian Peninsula'){
data_to_map[i,1]<-
-.01
}
if (countryRegions[i,'GEO3'] == 'Western Europe'){
data_to_map[i,1]<-
.06
}
if (countryRegions[i,'ADMIN'] == 'United Kingdom' | countryRegions[i,'ADMIN'] == 'Iceland'|
countryRegions[i,'ADMIN'] == 'Ireland' | countryRegions[i,'ADMIN'] == 'Finland'|
countryRegions[i,'ADMIN'] == 'Norway' | countryRegions[i,'ADMIN'] == 'Sweden'|
countryRegions[i,'ADMIN'] == 'Denmark' | countryRegions[i,'ADMIN'] == 'Estonia'|
countryRegions[i,'ADMIN'] == 'Latvia' | countryRegions[i,'ADMIN'] == 'Lithuania'){
data_to_map[i,1]<-
.23
}
if (countryRegions[i,'ADMIN'] == 'Spain' | countryRegions[i,'ADMIN'] == 'Portugal'|
countryRegions[i,'ADMIN'] == 'Slovenia' | countryRegions[i,'ADMIN'] == 'Croatia'|
countryRegions[i,'ADMIN'] == 'Andora' | countryRegions[i,'ADMIN'] == 'San Marino'|
countryRegions[i,'ADMIN'] == 'Vatican' | countryRegions[i,'ADMIN'] == 'Italy'|
countryRegions[i,'ADMIN'] == 'Malta' | countryRegions[i,'ADMIN'] == 'Republic of Serbia'|
countryRegions[i,'ADMIN'] == 'Greece' | countryRegions[i,'ADMIN'] == 'Albania'|
countryRegions[i,'ADMIN'] == 'Montenegro'| countryRegions[i,'ADMIN'] == 'Bosnia and Herzegovina'|
countryRegions[i,'ADMIN'] == 'Macedonia'|countryRegions[i,'ADMIN'] == 'Kosovo'){
data_to_map[i,1]<-
.03
}
}
# merge
df_to_map <- data.frame(
Country = countryRegions$ISO3,
Data = data_to_map
)
# map draw
sPDF <- joinCountryData2Map(df_to_map,
joinCode = 'ISO3',
nameJoinColumn = 'Country')
colourPalette <- brewer.pal(5,'RdPu')
mapCountryData(sPDF,nameColumnToPlot = 'Data',
catMethod='pretty', colourPalette=colourPalette,
mapTitle ='Acceptance of Sugar Relationships in Older Men and Women (ASR-OMWS) ')
mapCountryData(sPDF,nameColumnToPlot = 'Data',
catMethod='pretty', colourPalette=colourPalette,
mapTitle ='Cohen\'s D of ASR-YWMS - ASR-OWMS')
library(lordif)
load("~/Documents/Research/bDIT/MI/test.RData")
# plots
plot(now[[1]], mfrow=c(3,3
))
# plots
plot(now[[1]], mfrow=c(3,3
))
?plot.lordif.MC
?plog.lordif
?plot.lordif
?plot.lordif.MC
# plots
# gender
plot(now[[1]], mfrow=c(3,3
))
# plots
# gender
plot(now[[1]], mfrow=c(3,3
))
?plot.lordif.MC
# plots
# gender
plot(now[[1]], mfrow=c(3,3, width=4   ))
# plots
# gender
plot(now[[1]], mfrow=c(3,3 ), width=4  )
# plots
# gender
plot(now[[1]], mfrow=c(3,3 ), width=10  )
# plots
# gender
plot(now[[1]], mfrow=c(3,3 ), width=10, height=30  )
# plots
# gender
plot(now[[1]], mfrow=c(3,3 ), width=10, height=30  )
?plot
# plots
# gender
plot(now[[1]], mfrow=c(3,3 ), asp=1  )
# plots
# gender
plot(now[[1]], mfrow=c(3,3 ), asp=2  )
# plots
# gender
plot(now[[1]], mfrow=c(3,3 ), asp=1  )
# plots
# gender
plot(now[[1]], mfrow=c(3,3 ))
# plots
# gender
plot(now[[1]], mfrow=c(3,4 ))
# plots
# gender
plot(now[[1]], mfrow=c(4,3 ))
# plots
# gender
plot(now[[1]], mfrow=c(3,3 ))
# plots
# gender
plot(now[[1]], mfrow=c(3,3 ),graphics.off())
# plots
# gender
plot(now[[1]], mfrow=c(3,3 ),graphics.off(),height=10)
# plots
# gender
plot(now[[1]], mfrow=c(3,3 ),graphics.off(),height=10)
# plots
# gender
plot(now[[1]], mfrow=c(3,3 ),graphics.off(),height=10)
plot(now[[2]], mfrow=c(3,3),graphics.off())
plot(now[[3]], mfrow=c(3,3),graphics.off())
# politics
plot(now[[4]], mfrow=c(3,3),graphics.off())
plot(now[[5]], mfrow=c(3,3),graphics.off())
plot(now[[6]], mfrow=c(3,3),graphics.off())
# religion
plot(now[[7]], mfrow=c(3,3),graphics.off())
plot(now[[8]], mfrow=c(3,3),graphics.off())
plot(now[[9]], mfrow=c(3,3),graphics.off())
library(lavaan)
install.packages('lavaan')
install.packages("lavaan")
library(lavaan)
library(psychonetrics)
install.packages('psychonetrics')
install.packages("psychonetrics")
library(psychonetrics)
library(lvnet)
install.packages('OpenMx')
install.packages("OpenMx")
install.packages("OpenMx")
install.packages("OpenMx")
cpp_BFGS
cpp_BFGSlibrary(plyr        )
library(plyr        )
library(psych)
library(expss)
library(dplyr)
library(lavaan)
library(psychonetrics)
library(lvnet)
load("~/Documents/Research/bDIT/Network_test/Untitled.RData")
train.rnm.test.dist <- prune(modelsearch(stepup(prune(
runmodel(setoptimizer(
lrnm(data=train,lambda=lvmodel1$lambda,
estimator='FIML', omega_epsilon='full'),optimizer='default'
)
)))),adjust='fdr')
train.rnm.test.dist
rnm.test.dist <- setoptimizer(lrnm(data=testdata,lambda=lvmodel1$lambda,
estimator='FIML', omega_epsilon='full'),optimizer='default')
rnm.test.dist <- rnm.test.dist %>% runmodel
rnm.test.dist
rnm.test.dist <- setoptimizer(lrnm(data=testdata,lambda=lvmodel1$lambda,
estimator='FIML', omega_epsilon='full'),optimizer='default')
rnm.test.dist <- rnm.test.dist %>% runmodel( bounded=F)
rnm.test.dist
fit(rnm.test.dist)
?setoptimizer
rnm.test.dist <- setoptimizer(lrnm(data=testdata,lambda=lvmodel1$lambda,
estimator='FIML', omega_epsilon='full'),optimizer='nlminb')
rnm.test.dist
rnm.test.dist <- rnm.test.dist %>% runmodel( bounded=F)
rnm.test.dist
rnm.test.dist <- setoptimizer(lrnm(data=testdata,lambda=lvmodel1$lambda,
estimator='FIML', omega_epsilon='full'),optimizer='cpp_Nelder-Mead')
rnm.test.dist <- rnm.test.dist %>% runmodel( bounded=F)
rnm.test.dist
# bDIT test
model.story <- '
Ps =~ Q116 + Q132 + Q133 + Q134 + Q135 + Q136 + Q137 + Q138 +
Q139 + Q140 + Q141 + Q142 + Q143 + Q144 + Q145 + Q146 +
Q147 + Q148 + Q149 + Q150+
Q151 + Q152 + Q153 + Q154'
fit.story <- cfa(model.story,data=DATA,estimator='MLR')
# data extract
test1 <- lavPredict(fit.story,append.data = T)
testnames1 <- colnames(test1)[2:length(colnames(test1))]
testdata1 <- DATA[,testnames1]
lvmodel2<-lav2lvnet(model.story,data=testdata1)
lvmodel2$lambda[is.na(lvmodel2$lambda)]<-1
for.lambda<-data.frame(lvmodel2$lambda)
colnames(for.lambda)<-'Ps'
rnm.test.dist1 <- prune(modelsearch(stepup(prune(
runmodel(setoptimizer(
rnm(data=testdata1,lambda=data.matrix(for.lambda),
estimator='FIML', omega_epsilon='full'),optimizer='default'
)
)))),adjust='fdr')
rnm.test.dist1 <- rnm(data=testdata1,lambda=data.matrix(for.lambda),
estimator='FIML', omega_epsilon='full')
rnm.test.dist1<- runmodel(rnm.test.dist1)
rnm.test.dist1
library(lavaan)
sessionInfo()
install.packages('lavaan')
install.packages("lavaan")
install.packages("lavaan")
80+54+57
60+70+64+80+57
158+173
158/331
100/191
34/54
13+110
13/(13+110)
110/(13+110)
80/95
setwd("~/Documents/GitHub/R_Alignment_Test")
# measurement alignment test with Fisher & Karl (2019)
##### 0. Package importing and dataset loading
# package load
library(lavaan)
library(sirt)
library(foreach)
library(parallel)
library(doParallel)
library(psych)
library(MASS)
# set some constants
fits <- c('rmsea.scaled','srmr','cfi.scaled')
var.help <- c('help1','help2','help3','help4','help5','help6','help7')
# data load
data <- read.csv('example.csv')
DATA <- data
# how many countries?
table(data$country)
# eight countries
# sort by countries
data <- data[order(data$country),]
# extract country names
countries <- labels(table(data$country))[[1]]
##### 1. MG-CFA
#####
# first, let's start with MGCFA
# let's focus on help for now for alignment
cfa_model.help<- '
help =~ help1 + help2 + help3 + help4 + help5 + help6 + help7'
#  invariance test
# configural invariance
# use WLSMV (ordinal scale)
fit.help.configural <- cfa (cfa_model.help, data, group = 'country',
estimator='WLSMV')
fitMeasures(fit.help.configural)[fits]
#rmsea.scaled         srmr   cfi.scaled
#0.06855601   0.03272451   0.95127722
# metric invariance
fit.help.metric <- cfa (cfa_model.help, data, group = 'country',
estimator='WLSMV', group.equal='loadings')
fitMeasures(fit.help.metric)[fits]
#rmsea.scaled         srmr   cfi.scaled
#0.04358127   0.03944788   0.97292655
# changes
fitMeasures(fit.help.metric)[fits]-fitMeasures(fit.help.configural)[fits]
# -0.024974735  0.006723362  0.021649334
# acceptable
# scalar invariance
fit.help.scalar <- cfa (cfa_model.help, data, group = 'country',
estimator='WLSMV', group.equal=c('loadings','intercepts'))
fitMeasures(fit.help.scalar)[fits]
#rmsea.scaled         srmr   cfi.scaled
#0.05909330   0.04892335   0.93664870
# changes
fitMeasures(fit.help.scalar)[fits]-fitMeasures(fit.help.metric)[fits]
# 0.015512027  0.009475471 -0.036277857
# both rmsea and cfi changes exceeded threshold. alignment necessary
# residual invariance (just for testing)
fit.help.residual <- cfa (cfa_model.help, data, group = 'country',
estimator='WLSMV', group.equal=c('loadings','intercepts',
'residuals'))
fitMeasures(fit.help.residual)[fits]
#rmsea.scaled         srmr   cfi.scaled
#0.06703950   0.07359188   0.89808207
##### 2. Measurement Alignment
#####
# Then, let's perform measurement alignment
# help
# extract cfa parameters
par.help <- invariance_alignment_cfa_config(dat = data[,var.help],
group = data$country)
# do alignment
# following the suggested threshold values in Fisher & Karl (2019)
mod.help <- invariance.alignment(lambda = par.help$lambda, nu =
par.help$nu, align.scale = c(0.2, 0.4), align.pow = c(0.25, 0.25))
# test performance
mod.help$es.invariance['R2',]
#  loadings intercepts
# 0.9979870  0.9996975
# 99% absolbed -> great result
# item-level test
cmod <- invariance_alignment_constraints(mod.help, lambda_parm_tol = .4, nu_parm_tol = .2)
summary(cmod)
# lambda noninvariance item = 0%
# nu noninvariance item = 5.4%
# acceptable
# function to implement factor score calculation
# from adjusted lambda and nu
# basically, x = lambda*X + nu
# so, X = inv (lambda) (x - nu)
aligned.factor.scores <- function(lambda,nu,y){
#calculate inverse matrix
lambda1 <- ginv((lambda))
#create matrix for nu
ns <- nrow(y)
nus <- matrix(nu,nrow=ns, ncol=length(nu), byrow=T)
# y - nu
y_nu <- y - nu
F <- lambda1 %*% t(as.matrix(y_nu))
}
# calculate score
# do calculation for each country, and then merge
for (i in 1:(n.include)){
if (i == 1){
# first country
# create new matrix
data.aligned <- data[data$country==countries[i],]
# calculate factor score
Fs <- aligned.factor.scores(mod.help$lambda.aligned[i,],
mod.help$nu.aligned[i,],
data[data$country==countries[i],var.help])
data.aligned$help <- t(Fs)
}else{
# other than the first country
# append
current <- data[data$country==countries[i],]
Fs <- aligned.factor.scores(mod.help$lambda.aligned[i,],
mod.help$nu.aligned[i,],
data[data$country==countries[i],var.help])
current$help <- t(Fs)
data.aligned <- rbind(data.aligned,current)
}
}
length(countries)
##### 4. Factor Score Calculation
#####
# calculate factor scores based on aligned loadings and intercepts
# function to implement factor score calculation
# from adjusted lambda and nu
# basically, x = lambda*X + nu
# so, X = inv (lambda) (x - nu)
aligned.factor.scores <- function(lambda,nu,y){
#calculate inverse matrix of lambda
lambda1 <- ginv((lambda))
#create matrix for nu
ns <- nrow(y)
nus <- matrix(nu,nrow=ns, ncol=length(nu), byrow=T)
# y - nu
y_nu <- y - nu
F <- lambda1 %*% t(as.matrix(y_nu))
}
# calculate score
# do calculation for each country, and then merge
for (i in 1:(n.include)){
if (i == 1){
# first country
# create new matrix
data.aligned <- data[data$country==countries[i],]
# calculate factor score
Fs <- aligned.factor.scores(mod.help$lambda.aligned[i,],
mod.help$nu.aligned[i,],
data[data$country==countries[i],var.help])
data.aligned$help <- t(Fs)
}else{
# other than the first country
# append
current <- data[data$country==countries[i],]
Fs <- aligned.factor.scores(mod.help$lambda.aligned[i,],
mod.help$nu.aligned[i,],
data[data$country==countries[i],var.help])
current$help <- t(Fs)
data.aligned <- rbind(data.aligned,current)
}
}
# number of country groups to be examined
n.include <- length (countries)
##### 4. Factor Score Calculation
#####
# calculate factor scores based on aligned loadings and intercepts
# function to implement factor score calculation
# from adjusted lambda and nu
# basically, x = lambda*X + nu
# so, X = inv (lambda) (x - nu)
aligned.factor.scores <- function(lambda,nu,y){
#calculate inverse matrix of lambda
lambda1 <- ginv((lambda))
#create matrix for nu
ns <- nrow(y)
nus <- matrix(nu,nrow=ns, ncol=length(nu), byrow=T)
# y - nu
y_nu <- y - nu
F <- lambda1 %*% t(as.matrix(y_nu))
}
# calculate score
# do calculation for each country, and then merge
for (i in 1:(n.include)){
if (i == 1){
# first country
# create new matrix
data.aligned <- data[data$country==countries[i],]
# calculate factor score
Fs <- aligned.factor.scores(mod.help$lambda.aligned[i,],
mod.help$nu.aligned[i,],
data[data$country==countries[i],var.help])
data.aligned$help <- t(Fs)
}else{
# other than the first country
# append
current <- data[data$country==countries[i],]
Fs <- aligned.factor.scores(mod.help$lambda.aligned[i,],
mod.help$nu.aligned[i,],
data[data$country==countries[i],var.help])
current$help <- t(Fs)
data.aligned <- rbind(data.aligned,current)
}
}
corr.test(data.aligned$help,data.aligned$help1)
colnames(data.aligned)
data.aligned$HELP <- rowSums(data.aligned[,2:8])
corr.test(data.aligned$HELP,data.aligned$help)
